<!DOCTYPE html><html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type" /><meta content="width=device-width, initial-scale=1" name="viewport" /><!--replace-start-0--><!--replace-start-5--><!--replace-start-8--><title>the closed world - History Thesis Notes</title><!--replace-end-8--><!--replace-end-5--><!--replace-end-0--><link href="https://cdn.jsdelivr.net/npm/fomantic-ui@2.8.7/dist/semantic.min.css" rel="stylesheet" /><link href="https://fonts.googleapis.com/css?family=Merriweather|Libre+Franklin|Roboto+Mono&amp;display=swap" rel="stylesheet" /><!--replace-start-1--><!--replace-start-4--><!--replace-start-7--><link href="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" rel="icon" /><meta content="Myra Cheng" name="author" /><meta content="computers have hardware, whose heritage lies within the history of technology, and software, whose ancestry lies in mathematics and formal logic." name="description" /><link href="https://myracheng.github.io/closedworld" rel="canonical" /><meta content="the closed world" property="og:title" /><meta content="History Thesis Notes" property="og:site_name" /><meta content="article" property="og:type" /><meta content="closedworld" property="neuron:zettel-id" /><meta content="closedworld" property="neuron:zettel-slug" /><meta content="1940s" property="neuron:zettel-tag" /><script type="application/ld+json">[]</script><style type="text/css">body{background-color:#eeeeee !important;font-family:"Libre Franklin", serif !important}body .ui.container{font-family:"Libre Franklin", serif !important}body h1, h2, h3, h4, h5, h6, .ui.header, .headerFont{font-family:"Merriweather", sans-serif !important}body code, pre, tt, .monoFont{font-family:"Roboto Mono","SFMono-Regular","Menlo","Monaco","Consolas","Liberation Mono","Courier New", monospace !important}body div.z-index p.info{color:#808080}body div.z-index ul{list-style-type:square;padding-left:1.5em}body div.z-index .uplinks{margin-left:0.29999em}body .zettel-content h1#title-h1{background-color:rgba(0,181,173,0.1)}body nav.bottomPane{background-color:rgba(0,181,173,2.0e-2)}body div#footnotes{border-top-color:#00b5ad}body p{line-height:150%}body img{max-width:100%}body .deemphasized{font-size:0.94999em}body .deemphasized:hover{opacity:1}body .deemphasized:not(:hover){opacity:0.69999}body .deemphasized:not(:hover) a{color:#808080 !important}body div.container.universe{padding-top:1em}body div.zettel-view ul{padding-left:1.5em;list-style-type:square}body div.zettel-view .pandoc .highlight{background-color:#ffff00}body div.zettel-view .pandoc .ui.disabled.fitted.checkbox{margin-right:0.29999em;vertical-align:middle}body div.zettel-view .zettel-content .metadata{margin-top:1em}body div.zettel-view .zettel-content .metadata div.date{text-align:center;color:#808080}body div.zettel-view .zettel-content h1{padding-top:0.2em;padding-bottom:0.2em;text-align:center}body div.zettel-view .zettel-content h2{border-bottom:solid 1px #4682b4;margin-bottom:0.5em}body div.zettel-view .zettel-content h3{margin:0px 0px 0.4em 0px}body div.zettel-view .zettel-content h4{opacity:0.8}body div.zettel-view .zettel-content div#footnotes{margin-top:4em;border-top-style:groove;border-top-width:2px;font-size:0.9em}body div.zettel-view .zettel-content div#footnotes ol > li > p:only-of-type{display:inline;margin-right:0.5em}body div.zettel-view .zettel-content aside.footnote-inline{width:30%;padding-left:15px;margin-left:15px;float:right;background-color:#d3d3d3}body div.zettel-view .zettel-content .overflows{overflow:auto}body div.zettel-view .zettel-content code{margin:auto auto auto auto;font-size:100%}body div.zettel-view .zettel-content p code, li code, ol code{padding:0.2em 0.2em 0.2em 0.2em;background-color:#f5f2f0}body div.zettel-view .zettel-content pre{overflow:auto}body div.zettel-view .zettel-content dl dt{font-weight:bold}body div.zettel-view .zettel-content blockquote{background-color:#f9f9f9;border-left:solid 10px #cccccc;margin:1.5em 0px 1.5em 0px;padding:0.5em 10px 0.5em 10px}body div.zettel-view .zettel-content.raw{background-color:#dddddd}body .ui.label.zettel-tag{color:#000000}body .ui.label.zettel-tag a{color:#000000}body nav.bottomPane ul.backlinks > li{padding-bottom:0.4em;list-style-type:disc}body nav.bottomPane ul.context-list > li{list-style-type:lower-roman}body .footer-version img{-webkit-filter:grayscale(100%);-moz-filter:grayscale(100%);-ms-filter:grayscale(100%);-o-filter:grayscale(100%);filter:grayscale(100%)}body .footer-version img:hover{-webkit-filter:grayscale(0%);-moz-filter:grayscale(0%);-ms-filter:grayscale(0%);-o-filter:grayscale(0%);filter:grayscale(0%)}body .footer-version, .footer-version a, .footer-version a:visited{color:#808080}body .footer-version a{font-weight:bold}body .footer-version{margin-top:1em !important;font-size:0.69999em}@media only screen and (max-width: 768px){body div#zettel-container{margin-left:0.4em !important;margin-right:0.4em !important}}body span.zettel-link-container span.zettel-link a{color:#00b5ad;font-weight:bold;text-decoration:none}body span.zettel-link-container span.zettel-link a:hover{background-color:rgba(0,181,173,0.1)}body span.zettel-link-container span.extra{color:auto}body span.zettel-link-container.errors{border:solid 1px #ff0000}body span.zettel-link-container.errors span.zettel-link a:hover{text-decoration:none !important;cursor:not-allowed}body [data-tooltip]:after{font-size:0.69999em}body div.tag-tree div.node{font-weight:bold}body div.tag-tree div.node a.inactive{color:#555555}body .tree.flipped{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}body .tree{overflow:auto}body .tree ul.root{padding-top:0px;margin-top:0px}body .tree ul{position:relative;padding:1em 0px 0px 0px;white-space:nowrap;margin:0px auto 0px auto;text-align:center}body .tree ul::after{content:"";display:table;clear:both}body .tree ul:last-child{padding-bottom:0.1em}body .tree li{display:inline-block;vertical-align:top;text-align:center;list-style-type:none;position:relative;padding:1em 0.5em 0em 0.5em}body .tree li::before{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{right:auto;left:50%;border-left:solid 2px #cccccc}body .tree li:only-child{padding-top:0em}body .tree li:only-child::after{display:none}body .tree li:only-child::before{display:none}body .tree li:first-child::before{border-style:none;border-width:0px}body .tree li:first-child::after{border-radius:5px 0px 0px 0px}body .tree li:last-child::after{border-style:none;border-width:0px}body .tree li:last-child::before{border-right:solid 2px #cccccc;border-radius:0px 5px 0px 0px}body .tree ul ul::before{content:"";position:absolute;top:0px;left:50%;border-left:solid 2px #cccccc;width:0px;height:1.19999em}body .tree li div.forest-link{border:solid 2px #cccccc;padding:0.2em 0.29999em 0.2em 0.29999em;text-decoration:none;display:inline-block;border-radius:5px 5px 5px 5px;color:#333333;position:relative;top:2px}body .tree.flipped li div.forest-link{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}</style><script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css" rel="stylesheet" /><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/plugins/autoloader/prism-autoloader.min.js"></script><!--replace-end-7--><!--replace-end-4--><!--replace-end-1--></head><body><div class="ui fluid container universe"><!--replace-start-2--><!--replace-start-3--><!--replace-start-6--><div class="ui text container" id="zettel-container" style="position: relative"><div class="zettel-view"><article class="ui raised attached segment zettel-content"><div class="pandoc"><h1 id="title-h1">the closed world</h1><h2 id="preface">preface</h2><ol><li>intellectual history in which computers function primarily as the embodiment of ideas about information, symbols, and logic.</li></ol><ul><li>1956 consolidation of artificial intelligence research by John McCarthy, Marvin Minsky, Allen Newell, and Herbert Simon and the movement ofinformation theory into psychology through the work of George Miller, J. C. R. Licklider, and others in the late 1950s</li><li>In the late 1980s, the rise of parallel distributed processing and neural net- Preface xi works marks ever-closer convergence in the study of human and machine intelligence. Most of the characters in this version of the story are philosophers, scientists, or mathematicians concerned with logic. Very late in the game, some are psychologists using concepts of information processing to extend or overturn behaviorist models in favor of new cognitive theories. All are intellectuals and theorists</li><li>progress—knowledge expanding through a steady stream of new discoveries—and revolution</li><li>“computer revolution” of the 1950s linked calculation to communication, control, and simulation through new theories of information and symbolic programming. The “cognitive revolution” ofthe late 1950s carried these ideas to a wide range of previously divergent disciplines, such as psychology, linguistics, and neuroscience, bringing them new direction, linkage, and coherence.</li></ul><ol start="2"><li>engineering/economic history focusing on computers as devices for processing information.</li></ol><p>computers have hardware, whose heritage lies within the history of technology, and software, whose ancestry lies in mathematics and formal logic.</p><p>explain developments in a given held solely from the perspective of actors within it.</p><p>Mahoney puts it, the authors of this “insider history . . . take as givens . . . what a more critical, outside viewer might see as choices.”8</p><p>many layers of relationships: of individual scientists and engineers with military technical problems; of computer development projects with military agencies and their problems; of large-scale political trends with the direction and character of research; of computer metaphors with scientific research programs; and of cultural productions with scientific and technological changes</p><p>use metaphor and discourse</p><ul><li>techniqques, technologies, metaphors, and experiences as well as language. <em>Closed-world discourse</em> articulated geopolitical strategies and metaphors (such as “containing” Communism) in and through military systems for centralized command and control. <em>Cyborg discourse</em> articulated metaphors of minds as computers in and through integrated human-machine systems and technologies of artificial intelligence</li></ul><p>the role of industry was often closely co¬ ordinated with military plans.</p><p>This book attempts a kind of “counterhistory,” a corrective to perspectives that create the impression of an inevitable progress driven by impersonal market forces and technical logics. I</p><p>three apparently disparate histories—the history of American global power, the history of computing machines, and the history of mind and subjectivity as reflected in science and culture— through the lens of the American political imagination</p><p>computers connect cognitive psychology and artificial intelligence to high-technology warfare and to the institutional struc¬ ture of the modern state</p><p>historical links (which I have discussed elsewhere) between the traditionally extreme masculinity of the military world, the political culture of democracies, and the rationalistic masculinity of many computer cultures</p><h2 id="ch-1">ch 1</h2><p>the key theme of closed-world discourse was global surveillance and control through high-technology military power. Computers made the closed world work simultaneously as technology, as political system, and as ideological mirage.</p><h2 id="to-read">to read</h2><p>Howard Gardner’s The Mind’s New Science</p><p>§ee Allen Newell, “Intellectual Issues in the History of Artificial Intelli¬ gence,” i</p><p>Mahoney, “The History of Computing,” 114.</p><p>e Kenneth Flamm’s definitive two-volume economic history of comput¬ ers, Targeting the Computer</p><p>Paul N. Edwards, “The Army and the Microworld: Computers and the Militarized Politics of Gender,” Signs, Vol. 16, No. 1 (1990), 102-127.</p><h2 id="chapter-1">chapter 1</h2><p>Closed-world discourse helped guide U.S. military policy into an extreme reliance on computers and other high-technology weapons.</p><p>Cyborg discourse collaborated with closed-world discourse both materially, when artificial intelligence technologies and human/machine integration techniques were used for military purposes, and metaphorically, by creating an interpretation of the inner world of human psychology as a closed and technically manipulable system</p><p>This section ex¬ plores the nature of computers, the relation between tools and metaphors, and the theory of discourse upon which this book relies. (Readers whose eyes glaze over at the word “theory” should feel free to skip this section, referring back to it only as necessary</p><h2 id="chapter-2">chapter 2</h2><p>till 60’s, armed forces are driver of digital computer development finanical importance also, significance of military involvement: why did military agencies provide such lavish fundign?</p><p>it was often civilians who pushed applications of computers to military problems</p><p>ww ii: artillary and anti-aircraft systems</p><p>cybernetics: major precursor of cogitive psychology</p><p>Bush differential analyzer</p><ul><li><p>administrative leadership, established National Defense Research Committee (NDRC) –&gt; became OSRD, critical in WII</p></li><li><p>system of large central laboratories</p><ul><li>The war effort thus brought about the most radical disciplinary mixing, administrative centralization, and social reorganization of science and engineering ever attempted in the United States</li><li>e vast interdisciplinary effort profoundly restructured scientific research communities. It solidified the trend to science-based industry—already entrenched in the interwar years—but it added the new ingredient of massive government funding and military direction</li></ul></li><li><p>MIT a research budget ten times as large—85 percent from the military services</p></li><li><p>“iron triangle”: See David Noble, America By Design: Science, Technology, and the Rise of Corporate Capitalism (Oxford: Oxford University Press, 1977), as well as Dickson, New Politics of Science, and Merritt Roe Smith, ed., Military Enterprise and Technological Change (Cambridge, MA: MIT Press, 1985). The phrase “iron triangle” is from Gordon Adams, The Politics of Defense Cont</p></li><li><p>creation of an unprecedented experience of community among scientists and engineers</p></li></ul><h4 id="eniac">eniac</h4><p>The ENIAC represented an electrical engineering project of a com¬ pletely unp</p><p>great mathematician John von Neumann became involved with the ENIAC project in 1944, after a chance encounter with Her¬ man Goldstine on a train platform</p><p>EDVAC “von neuman architectures”</p><p>The ENIAC became, like radar and the bomb, an icon of the miracle of government-supported “big science.”</p><p><span><code class="inline-tag">#1940s</code></span> The wartime alliance of academic and industrial science with the military had begun as a temporary association for a limited purpose: winning a war against aggressors. Now it was crystallizing into a permanent union.</p><p>he “anti-power ethic” in American society, the enormous value this society has always placed on political limits to power, hierarchy, and authority.35</p><p>Office of Naval Research in 1946. In a pattern repeated again and again during the Cold War, national security provided the consensual justification for federally funded research</p><p>Even after 1967, the only period for which reliable statistics are available, the NSF’s share of total federal funding for computer science hovered consistently around the 20 per¬ cent mark, while Department of Defense obligations ranged between 50 and 70 percent</p><p>Flamm, Targeting the Computer</p><h3 id="postwar">postwar</h3><p>Bell Laboratories, the largest independent electronics research laboratory in the country, saw the percentage of its peacetime budget allocated to military projects swell from zero (prewar) to upwards of 10 percent as it continued work on the Nike missile and other systems, many of them involving analog computers</p><p>Flamm estimates that in 1950 the federal government provided between $15 and $20 million (current) per year, while industry contributed less than $5 million—20 to 25 percent of the total. The vast bulk of federal research funds at that time came from military agencie</p><h3 id="consequences">consequences</h3><p>fast pace, outpaced the british</p><p>military secrecy surrounding both british and american research - IAS widely dessemminated –&gt; continued tradition of secrecy</p><p>even after mature commercial computer markets emerged in the early 1960s, U.S. military agencies continued to invest heavily in advanced computer research, equipment, and software. In the 1960s the private sector gradually assumed the bulk of R&amp;D funding. IBM, in particular, adopted a strategy of heavy investment in re¬ search, reinvesting over 50 percent of its profits in internal R&amp;cD after 1959.</p><p>To compete, other companies eventually duplicated IBM’s pattern of internal research investment.</p><p>but pentagon dominated research funding, - almost half of the cost of semiconductor R&amp;D between the late 1950s and the early 1970s was paid by military sources.</p><p>AI: nurturance of artificial intelligence (AI) by the Advanced Research Projects Agency (AJRPA, later called DARPA, the Defense Advanced Research Projects Agency), which ex¬ tended from the early 1960s until the final end of the Cold War</p><p>AI, for over two decades almost exclusively a pure research area of no im¬ mediate commercial interest, received as much as 80 percent of its total annual funding from ARPA</p><p>the pattern of military support has been widespread, longlasting, and deep. In part because of connections dating to the Why Build Computers ? 65 ENIAC and before, this pattern became deeply ingrained in postwar institutions</p><h2 id="why">why</h2><ul><li>speed and complexity of high-technology warfare have generated control, communications, and information analysis de¬ mands that seem to defy the capacities of unassisted human beings.</li><li>command, control, communications, and intelligence (or information) networks, replacing and assisting humans in the encoding and decoding of messages, the interpretation of radar data, and tracking and targeting functions, among many others.<ul><li>this is a RETROSPECTIVE CONSTRUCTION. analog made much more seese</li></ul></li></ul><p>Deep theoretical linkages among the three functions were already being articulated in the communication and information theories of Norbert Wiener and Claude Shannon</p><p><strong>the evolution of practical design projects in social and cultural context</strong> lots of investment into analog digital was a threat to analog</p><ul><li>social inertia, easy availability, and an acculturated preference for analog technology,</li></ul><p>Only in the 1980s did efficient digital parallel processing become possible, motivated in part by precisely this issue of real-time control.</p><ul><li><p>in the decade following World War II digital computers were a technology at the early phase of development that Trevor Pinch and Wiebe Bijker describe as, in essence, a solution in search of a problem</p></li><li><p>the use of digital devices to create automated, centralized military command-control systems was anything but foreordained.</p></li></ul><p>The automation theory alone, then, explains neither the urgency, the magnitude, nor the specific direction of the U.S. military effort in com¬ puting - utiliarian writing history backwards</p><ul><li>why fascination?</li></ul><p>policy choices at the largest levels determined research directions, in some cases quite specifically, defin¬ ing digital computation as relevant to national priorities was not itself a policy issue. Instead it involved a complicated nexus of technologi¬ cal choices, technological traditions, and cultural value</p><p>p 101</p><h2 id="ch-6">ch 6</h2><p>p 201</p><p>hixon symposium n intellec¬ tual revolution opens with bigger and better robots. The former revolution replaced muscles by engines and was limited by the law of the conservation of energy, or of mass-energy. The new revolution threatens us, the thinkers, with technological unemployment, for it will replace brains with machines limited by the law that entropy never decreases.</p><p>Knowledge of the mind as an information-processing de¬ vice developed in just such a “circular relation” to high-technology military power.</p><p>federal government directly employed about half of all professional psychologists, either on research contracts, in military service, or in civilian agencies</p><p>cognitive psychology reconstructed both hu¬ mans and animals as cybernetic machines and digital computers. The explicit goal of the proto-cognitive theories of the 1940s and 195</p><p>p 209</p><p>Feedback Mechanisms and Circular Causal Systems in Biology and the Social Sciences Meeting,</p><p>Comparing the group’s “overenthusiasm” to the premature popularity of phrenology in the 1800s, he begged for intellectual “responsibility” in the use of cybernetic terminology</p><p>Particular ideas of “information” and “communication, ” derived in part from wartime engineering experience.</p><p>e how a group whose central concerns were profoundly shaped by some of its members’ experiences with military engineering problems continued to think in terms of those problems and created from them a new field ofscientific possibilities. T</p><p>psychological phenomena defined, for them, in terms of the tracking, targeting, and communications tasks ofthe war.</p><p>vision as tracking</p><p>shannon, communication speech</p><h2 id="ch-8-ai">ch 8 AI</h2><p>AI’s story has been written as a pure history of ideas</p><p>, sets the birth of a new sci¬ ence against a wider background of postwar practical needs, political discourses, and social networks</p><p>mimic minds in software, whereas cybernetics mimics it in hardware</p><p>shift in orientation from process to function</p><p>e 1956 Dartmouth conference, the birthplace of AI as a system¬ atic research program, the rift between brain modeling and symbolic processing rem</p><p>Links, almost fortuitous in nature, between AI and time-sharing systems brought the budding discipline into close connection with military projects for human-machine integration in command-control systems</p><p>he Information Processing Techniques Office (IPTO) of the Advanced Research Projects Agency (ARPA). IPTO’s founder, PAL and SAGE veteran J. C. R. Licklider, aggressively promoted a vision of computerized military command and control that helped to shape the AI research agenda for the next twenty-five years.</p><p>for this generation, computers appeared not primarily as tools for solving practical problems, but as automated mathematical models with a powerful intellectual appeal.</p><p>A computer programmed to carry out the same steps would thus be doing exactly the same thing as the person</p><p>Turing’s focus on learning gave his ideas about intelligent machines a quasi-biological cast, while his method of symbolic programming more closely resembled what AI would eventually become. Thus this work occupied a transitional place between the brain models of cybernetics and the symbolic processors of artificial intelligence.</p><p>e Office of Naval Research sponsored symposia on “automatic programming” in 1954 and 1956</p><p>AI systems were highly structured, manipulating pre-encoded and pre-organized knowledge rather than building it through sensory encounters. Instead of feedback, reflex, and neural networks, the AI theorists thought in terms of instruc¬ tions, languages, goals, and logical operations.</p><p>Dartmouth conference is generally recognized as the conceptual birthplace of AI (though Newell and Simon’s work in fact predates it). The second MIT Symposium on Information Theory, from which George Miller dates the inception of cognitive psychology, occurred a few months later, and its protagonists included many of the same people</p><p>1958 McCarthy and Minsky had teamed up to establish an Arti¬ ficial Intelligence Group at MI T’s Research Laboratory of Electronics. That year McCarthy “proposed that all human knowledge be given a</p><p>AI sought to enclose and reproduce the world within the horizon and the language of systems and information</p><p>recommended acquiring an “extremely fast” computer with a “very large core memory” and a time-sharing operating system as the solution to the time bottleneck.3</p><p>McCarthy’s time-sharing idea bore no inherent connection to AI. It was simply an efficient kind of operating system, an alternative way of constructing the basic hardware and software that controls how the computer processes programs. Yet AI work influenced his invention of time-sharing in two major ways:</p><ol><li>ai used a lot of memory</li><li>needed time-sharing to provide the right subjective environment for AI work. He promoted time-sharing “as something for artificial intelligence, for I’d designed LISP in such a way that working with it interactively—giving it a command, then seeing what happened, then giving it another command—was the best way to work with it.”</li></ol><p>wanted to interact w computers</p><p>change in in the basic social structure and the subjective environment of computer work</p><p>interactive access</p><h3 id="arpa">arpa</h3><p>The ONR had long since decided that future military forces would require computer technologies for “decision support.” As Marvin Denicoff, one of its leaders, later recalled, “In the early fifties, it oc¬ curred to some of us [at the ONR] that we ought to begin supporting decision makers where that decision maker could be an inventory specialist, a command and control specialist, a tactical officer, a battle¬ field officer, a pilot—any of many categories. Also, we should begin to go out to universities that had strong programs or emerging programs in computation and fund them.” [37] Marvin Denicoff, “AI Development and the Office of Naval Research,” in Thomas C. Bartee, ed., Expert Systems and Artificial Intelligence (Indianapolis: Howard W. Sams &amp; Co., 1988), 272</p><p>e features of ARPA sponsorship had the effect of permanently “addicting” ARPA-supported laboratories to Defense Department funding See Terry Winograd, “Strategic Computing Research and the Universi¬ ties,” in Charles Dunlop and Rob Kling, eds., Computerization and Controversy (New York: Academic Press, 1991), 704-716</p><p>denicoff memoir: similarity between the opera¬ tions research (OR) methods familiar to the ONR’s leaders and the emerging programming techniques of AI. AI sought close fits, best approximations, and heuristic rules</p><p>When McCarthy planned the 1956 Dartmouth conference, the ONR gladly footed part of the bill. By then it had already sought out Newell, Simon, and oth¬ ers at Carnegie Tech and the Graduate School of Industrial Adminis¬ tration (where Simon taught): “We wrote a long-term contract essentially to explore new approaches to decision making with all of those people [from Carnegie] involved</p><p>Licklider and his Information Processing Techniques Office, the closed-world military goais of decision support and computerized command and control found a unique relationship to the cyborg discourses of cognitive psychology and artificial intelligence</p><p>ARPA: to advance defense technology in many critical areas and to help the DoD cre¬ ate military capabilities of a character that the Military Services and Depart¬ ments were not able or willing to develop for any of several reasons</p><p>ARPA reincarnated the World War II OSRD</p><p>ARPA concen¬ trated its funding in a small number of elite “centers of excellence,” primarily in universities. Lacking both heavy congressional oversight and the development orientation of the services, the agency could support far-sighted, high-risk projects that might help avoid “techno¬ logical surprises” (in the phraseology of a later era) from other countries</p><h3 id="licklider">licklider</h3><p>organized the psychological side of the Lincoln Laboratory “presentation group” responsible for SAGE interface desig</p><p>Licklider’s career path, like George Miller’s, demonstrates how military research problems, and a location within institutions dedicated to their solution, could shape scientists’ intellectual interests and visions of the future</p><p>played a major role in its construction as a problem of command and control</p><p>MIT’s Project MAC, begun in 1963. MAC stood variously for Man and Computer, Machine-Aided Cognition, or Multi-Access Computing. With a mandate broader than that of the SDC, Project MAC explored a wide range of interactive computing technologies.</p><p>SAIL: In 1962, John McCarthy had left MIT to join the growing computer science group at Stanford University. The following year, soon after Project MAC began, he founded the Stanford AI Laboratory, which immediately became another major locus of AI research. Funding from ARPA was virtually automatic; Licklider simply asked McCarthy what he wanted and then gave it to him, a procedure unthinkable for most other government agencies. Licklider remembered that “it seemed obvious to me that he should have a laboratory supported by ARPA. … So I wrote him a contract at that time.”65</p><p>IPTO As the project with the least immediate utility and the farthest-reaching ambitions, AI came to rely unusually heavily on ARPA funding</p><p>, the military utility of research programs aimed at integrating humans and machines.</p></div><div class="metadata"><div class="date" title="Zettel date"><time datetime="2021-04-12T17:25">2021-04-12</time></div></div></article><nav class="ui attached segment deemphasized backlinksPane" id="neuron-backlinks-pane"><h3 class="ui header">Backlinks</h3><ul class="backlinks"><li><span class="zettel-link-container cf"><span class="zettel-link"><a href="payette">payette</a></span></span><ul class="context-list" style="zoom: 85%;"><li class="item"><div class="pandoc"><p>In The Closed World, Edwards argued that to fully understand the computer, we must uncover the social and political meanings that include the conceptual models we build, the metaphors we use, and the experiences we have with the computer <span class="zettel-link-container cf"><span class="zettel-link" title="2021-04-12T17:25"><a href="closedworld">the closed world</a></span></span> were from different generations, had radically different entry points into computing</p></div></li></ul></li></ul></nav><nav class="ui attached segment deemphasized bottomPane" id="neuron-tags-pane"><div><span class="ui basic label zettel-tag" title="Tag">1940s</span></div></nav><nav class="ui bottom attached icon compact inverted menu teal" id="neuron-nav-bar"><!--replace-start-9--><a class="item" href="." title="Home"><i class="home icon"></i></a><!--replace-end-9--><a class="item" href="https://github.com/myracheng/hthesis22/edit/master/./closedworld.md" title="Edit this page"><i class="edit icon"></i></a><a class="right item" href="impulse" title="Open Impulse"><i class="wave square icon"></i></a></nav></div></div><!--replace-end-6--><!--replace-end-3--><!--replace-end-2--><div class="ui center aligned container footer-version"><div class="ui tiny image"><a href="https://neuron.zettel.page"><img alt="logo" src="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" title="Generated by Neuron 1.9.35.3" /></a></div></div></div></body></html>