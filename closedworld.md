---
date: 2021-04-12T17:25
---

# the closed world

## preface

1. intellectual history in which computers function primarily as the embodiment of ideas about information, symbols, and logic.
- 1956 consolidation of artificial intelligence research by John McCarthy, Marvin Minsky, Allen Newell, and Herbert Simon and the movement ofinformation theory into psychology through the work of George Miller, J. C. R. Licklider, and others in the late 1950s
- In the late 1980s, the rise of parallel distributed processing and neural net- Preface xi works marks ever-closer convergence in the study of human and machine intelligence. Most of the characters in this version of the story are philosophers, scientists, or mathematicians concerned with logic. Very late in the game, some are psychologists using concepts of information processing to extend or overturn behaviorist models in favor of new cognitive theories. All are intellectuals and theorists
- progress—knowledge expanding through a steady stream of new discoveries—and revolution
- “computer revolution” of the 1950s linked calculation to communication, control, and simulation through new theories of information and symbolic programming. The “cognitive revolution” ofthe late 1950s carried these ideas to a wide range of previously divergent disciplines, such as psychology, linguistics, and neuroscience, bringing them new direction, linkage, and coherence.
2. engineering/economic history focusing on
computers as devices for processing information.

computers have
hardware, whose heritage lies within the history of technology, and software, whose ancestry lies in mathematics and formal logic. 

explain developments in a given held solely from the perspective of actors within it.

 Mahoney puts
it, the authors of this “insider history . . . take as givens . . . what a
more critical, outside viewer might see as choices.”8 


many layers of relationships: of individual scientists and engineers with military technical problems; of computer development projects with military agencies and their problems; of large-scale political trends with the direction and character of research; of computer metaphors with scientific research programs; and of cultural productions with scientific and technological changes

use metaphor and discourse
- techniqques, technologies, metaphors, and experiences as well as language. *Closed-world discourse* articulated geopolitical strategies and metaphors (such as “containing” Communism) in and through military systems for centralized command and control. *Cyborg discourse* articulated metaphors of minds as computers in and through integrated human-machine systems and technologies of artificial intelligence

the role of industry was often closely co¬
ordinated with military plans.


This book attempts a kind of “counterhistory,” a corrective to perspectives that create the impression of an inevitable progress driven by impersonal market forces and technical logics. I


three apparently disparate histories—the history of American global power, the history of computing machines, and the history of mind and subjectivity as reflected in science and culture— through the lens of the American political imagination

computers connect cognitive psychology and artificial
intelligence to high-technology warfare and to the institutional struc¬
ture of the modern state


historical links (which I have discussed elsewhere) between the traditionally extreme masculinity of the military world, the political culture of democracies, and the rationalistic masculinity of many computer cultures

## ch 1
the key theme of closed-world discourse was global surveillance and control through high-technology military power. Computers made the closed world work simultaneously as technology, as political system, and as ideological mirage.

## to read
Howard Gardner’s The Mind’s New Science


§ee Allen Newell, “Intellectual Issues in the History of Artificial Intelli¬
gence,” i

Mahoney, “The History of Computing,” 114.

e Kenneth Flamm’s definitive two-volume economic history of comput¬
ers, Targeting the Computer


Paul N. Edwards, “The Army and the Microworld: Computers and the
Militarized Politics of Gender,” Signs, Vol. 16, No. 1 (1990), 102-127.


## chapter 1
Closed-world discourse helped guide U.S. military policy into an extreme reliance on computers and other high-technology weapons.

Cyborg discourse collaborated with closed-world discourse both materially, when artificial intelligence technologies and human/machine integration techniques were used for military purposes, and metaphorically, by creating an interpretation of the inner world of human psychology as a closed and technically manipulable system

This section ex¬
plores the nature of computers, the relation between tools and
metaphors, and the theory of discourse upon which this book relies.
(Readers whose eyes glaze over at the word “theory” should feel free
to skip this section, referring back to it only as necessary

## chapter 2
till 60's, armed forces are driver of digital computer development
finanical importance
also, significance of military involvement:
why did military agencies provide such lavish fundign?

it was often civilians who pushed applications of computers to military problems


ww ii:
artillary and anti-aircraft systems

cybernetics: major precursor of cogitive psychology

Bush differential analyzer
- administrative leadership, established National Defense Research Committee (NDRC) --> became OSRD, critical in WII
- system of large central laboratories
    - The war effort thus brought about the most radical disciplinary mixing, administrative centralization, and social reorganization of science and engineering ever attempted in the United States
    - e vast interdisciplinary effort profoundly restructured scientific research communities. It solidified the trend to science-based industry—already entrenched in the interwar years—but it added the new ingredient of massive government funding and military direction
- MIT a research budget ten times as large—85 percent from the military services

- "iron triangle": See David Noble, America By Design: Science, Technology, and the Rise of Corporate Capitalism (Oxford: Oxford University Press, 1977), as well as Dickson, New Politics of Science, and Merritt Roe Smith, ed., Military Enterprise and Technological Change (Cambridge, MA: MIT Press, 1985). The phrase “iron triangle” is from Gordon Adams, The Politics of Defense Cont

- creation of an unprecedented experience of community among scientists and engineers

#### eniac
The ENIAC represented an electrical engineering project of a com¬
pletely unp

great mathematician John von Neumann became involved
with the ENIAC project in 1944, after a chance encounter with Her¬
man Goldstine on a train platform

EDVAC "von neuman architectures"

The ENIAC became, like radar and the bomb, an icon of the miracle of government-supported “big science.”

#1940s
The wartime alliance of academic and industrial science with the military had begun as a temporary association for a limited purpose: winning a war against aggressors. Now it was crystallizing into a permanent union.

he “anti-power ethic” in American society, the enormous value
this society has always placed on political limits to power, hierarchy,
and authority.35

Office of Naval Research in 1946. In a pattern repeated again and again during the Cold War, national security provided the consensual justification for federally funded research

Even after 1967, the only period
for which reliable statistics are available, the NSF’s share of total federal
funding for computer science hovered consistently around the 20 per¬
cent mark, while Department of Defense obligations ranged between 50
and 70 percent

Flamm, Targeting the
Computer

### postwar
Bell Laboratories, the largest independent electronics research laboratory in the country, saw the percentage of its peacetime budget allocated to military projects swell from zero (prewar) to upwards of 10 percent as it continued work on the Nike missile and other systems, many of them involving analog computers

Flamm estimates that in 1950 the federal government provided between $15 and $20 million (current) per year, while industry contributed less than $5 million—20 to 25 percent of the total. The vast bulk of federal research funds at that time came from military agencie

### consequences
fast pace, outpaced the british

military secrecy surrounding both british and american research
    - IAS widely dessemminated
--> continued tradition of secrecy

even after mature commercial computer markets emerged
in the early 1960s, U.S. military agencies continued to invest heavily
in advanced computer research, equipment, and software. In the
1960s the private sector gradually assumed the bulk of R&D funding.
IBM, in particular, adopted a strategy of heavy investment in re¬
search, reinvesting over 50 percent of its profits in internal R&cD after
1959.

To compete, other
companies eventually duplicated IBM’s pattern of internal research
investment.

but pentagon dominated research funding, 
    - almost half of the cost of semiconductor
R&D between the late 1950s and the early 1970s was paid by military
sources.

AI: nurturance of artificial intelligence (AI)
by the Advanced Research Projects Agency (AJRPA, later called
DARPA, the Defense Advanced Research Projects Agency), which ex¬
tended from the early 1960s until the final end of the Cold War

AI,
for over two decades almost exclusively a pure research area of no im¬
mediate commercial interest, received as much as 80 percent of its
total annual funding from ARPA

the pattern of military support has been widespread, longlasting, and deep. In part because of connections dating to the
Why Build Computers ? 65
ENIAC and before, this pattern became deeply ingrained in postwar
institutions

## why
- speed and complexity of high-technology warfare have
generated control, communications, and information analysis de¬
mands that seem to defy the capacities of unassisted human beings.
- command, control, communications, and intelligence (or information) networks, replacing and assisting humans in the encoding and decoding of messages, the interpretation of radar data, and tracking and targeting functions, among many others.
    - this is  a RETROSPECTIVE CONSTRUCTION. analog made much more seese



Deep theoretical linkages among the three functions were already
being articulated in the communication and information theories of
Norbert Wiener and Claude Shannon

**the evolution of practical design projects in social and cultural context**
lots of investment into analog
digital was a threat to analog
- social inertia, easy availability, and an acculturated
preference for analog technology,


Only in the 1980s did efficient digital parallel processing become
possible, motivated in part by precisely this issue of real-time control.
- in the decade following World War II digital computers
were a technology at the early phase of development that Trevor
Pinch and Wiebe Bijker describe as, in essence, a solution in search of
a problem

- the use of digital devices to create automated, centralized military
command-control systems was anything but foreordained.


The automation theory alone, then, explains neither the urgency, the
magnitude, nor the specific direction of the U.S. military effort in com¬
puting
    - utiliarian writing history backwards

- why fascination?

policy choices at the largest levels
determined research directions, in some cases quite specifically, defin¬
ing digital computation as relevant to national priorities was not itself
a policy issue. Instead it involved a complicated nexus of technologi¬
cal choices, technological traditions, and cultural value

p 101

## ch 6 
p 201

hixon symposium
n intellec¬
tual revolution opens with bigger and better robots. The former revolution
replaced muscles by engines and was limited by the law of the conservation of
energy, or of mass-energy. The new revolution threatens us, the thinkers,
with technological unemployment, for it will replace brains with machines
limited by the law that entropy never decreases.


Knowledge of the mind as an information-processing de¬
vice developed in just such a “circular relation” to high-technology
military power.

federal government directly employed about half of all
professional psychologists, either on research contracts, in military
service, or in civilian agencies

cognitive psychology reconstructed both hu¬
mans and animals as cybernetic machines and digital computers. The
explicit goal of the proto-cognitive theories of the 1940s and 195

p 209

Feedback Mechanisms and Circular
Causal Systems in Biology and the Social Sciences Meeting,

Comparing the group’s “overenthusiasm” to the premature popularity of phrenology in the 1800s, he begged for intellectual “responsibility” in the use of cybernetic terminology

Particular ideas of “information” and “communication, ” derived in part
from wartime engineering experience.

e how a group whose central concerns were
profoundly shaped by some of its members’ experiences with military
engineering problems continued to think in terms of those problems
and created from them a new field ofscientific possibilities. T

psychological phenomena defined, for them, in
terms of the tracking, targeting, and communications tasks ofthe war.

vision as tracking


shannon, communication speech


## ch 8 AI
AI’s story has been
written as a pure history of ideas

, sets the birth of a new sci¬
ence against a wider background of postwar practical needs, political
discourses, and social networks

mimic minds in software, whereas cybernetics mimics it in hardware

shift in orientation from process
to function

e 1956 Dartmouth conference, the birthplace of AI as a system¬
atic research program, the rift between brain modeling and symbolic
processing rem

Links, almost
fortuitous in nature, between AI and time-sharing systems brought
the budding discipline into close connection with military projects for
human-machine integration in command-control systems

he Information Processing Techniques Office (IPTO) of the
Advanced Research Projects Agency (ARPA). IPTO’s founder, PAL
and SAGE veteran J. C. R. Licklider, aggressively promoted a vision
of computerized military command and control that helped to shape
the AI research agenda for the next twenty-five years.

for this generation, computers appeared not primarily as tools for solving practical problems, but as automated mathematical models with a powerful intellectual appeal.

 A computer programmed to carry out the same steps would
thus be doing exactly the same thing as the person

Turing’s focus on learning gave his ideas about intelligent machines a quasi-biological cast, while his method of symbolic programming more closely resembled what AI would eventually become. Thus this work occupied a transitional place between the brain models of cybernetics and the symbolic processors of artificial intelligence.


e Office of Naval Research sponsored symposia
on “automatic programming” in 1954 and 1956

AI systems were highly structured,
manipulating pre-encoded and pre-organized knowledge rather than
building it through sensory encounters. Instead of feedback, reflex,
and neural networks, the AI theorists thought in terms of instruc¬
tions, languages, goals, and logical operations.

Dartmouth conference is
generally recognized as the conceptual birthplace of AI (though
Newell and Simon’s work in fact predates it). The second MIT Symposium on Information Theory, from which George Miller dates the
inception of cognitive psychology, occurred a few months later, and
its protagonists included many of the same people

1958 McCarthy and Minsky had teamed up to establish an Arti¬
ficial Intelligence Group at MI T’s Research Laboratory of Electronics.
That year McCarthy “proposed that all human knowledge be given a

AI sought to enclose and reproduce the world
within the horizon and the language of systems and information

recommended acquiring an “extremely fast” computer with a “very large core memory” and a time-sharing operating system as the solution to the time bottleneck.3

McCarthy’s time-sharing idea bore no inherent connection to AI. It was simply an efficient kind of operating system, an alternative way of constructing the basic hardware and software that controls how the computer processes programs. Yet AI work influenced his invention of time-sharing in two major ways:
1) ai used a lot of memory
2) needed time-sharing to provide the right subjective environment for AI work. He promoted time-sharing “as something for artificial intelligence, for I’d designed LISP in such a way that working with it interactively—giving it a command, then seeing what happened, then giving it another command—was the best way to work with it.”

wanted to interact w computers

change in in the basic social structure and
the subjective environment of computer work

interactive access

### arpa

The ONR had long since decided that future military forces would
require computer technologies for “decision support.” As Marvin
Denicoff, one of its leaders, later recalled, “In the early fifties, it oc¬
curred to some of us [at the ONR] that we ought to begin supporting
decision makers where that decision maker could be an inventory
specialist, a command and control specialist, a tactical officer, a battle¬
field officer, a pilot—any of many categories. Also, we should begin to
go out to universities that had strong programs or emerging
programs in computation and fund them.” [37] Marvin Denicoff, “AI Development and the Office of Naval Research,” in Thomas C. Bartee, ed., Expert Systems and Artificial Intelligence (Indianapolis: Howard W. Sams & Co., 1988), 272

e features
of ARPA sponsorship had the effect of permanently “addicting”
ARPA-supported laboratories to Defense Department funding
See Terry Winograd, “Strategic Computing Research and the Universi¬
ties,” in Charles Dunlop and Rob Kling, eds., Computerization and Controversy
(New York: Academic Press, 1991), 704-716

denicoff memoir:
similarity between the opera¬
tions research (OR) methods familiar to the ONR’s leaders and the
emerging programming techniques of AI. AI sought close
fits, best approximations, and heuristic rules

When McCarthy
planned the 1956 Dartmouth conference, the ONR gladly footed part
of the bill. By then it had already sought out Newell, Simon, and oth¬
ers at Carnegie Tech and the Graduate School of Industrial Adminis¬
tration (where Simon taught): “We wrote a long-term contract
essentially to explore new approaches to decision making with all of
those people [from Carnegie] involved

Licklider and his Information Processing Techniques Office, the closed-world military goais of decision support and computerized command and control found a unique relationship to the cyborg discourses of cognitive psychology and artificial intelligence

ARPA: to advance defense technology in many critical areas and to help the DoD cre¬
ate military capabilities of a character that the Military Services and Depart¬
ments were not able or willing to develop for any of several reasons

ARPA reincarnated the
World War II OSRD

ARPA concen¬
trated its funding in a small number of elite “centers of excellence,”
primarily in universities. Lacking both heavy congressional oversight
and the development orientation of the services, the agency could
support far-sighted, high-risk projects that might help avoid “techno¬
logical surprises” (in the phraseology of a later era) from other
countries

### licklider
organized the psychological side of the Lincoln Laboratory “presentation group” responsible for SAGE interface desig

Licklider’s career path, like George Miller’s, demonstrates how military research problems, and a location within institutions dedicated to their solution, could shape scientists’ intellectual interests and visions of the future

played a major role in its construction as a problem of command and control

MIT's Project MAC, begun in 1963. MAC stood variously for Man and Computer, Machine-Aided Cognition, or Multi-Access Computing. With a mandate broader than that of the SDC, Project MAC explored a wide range of interactive computing technologies.

SAIL:
In 1962, John McCarthy had left MIT to join the growing computer science group at Stanford University. The following year, soon after Project MAC began, he founded the Stanford AI Laboratory, which immediately became another major locus of AI research. Funding from ARPA was virtually automatic; Licklider simply asked McCarthy what he wanted and then gave it to him, a procedure unthinkable for most other government agencies. Licklider remembered that “it seemed obvious to me that he should have a laboratory supported by ARPA. ... So I wrote him a contract at that time.”65

IPTO 
As the project with the least immediate utility and the farthest-reaching ambitions, AI came to rely unusually heavily on ARPA funding

, the military utility
of research programs aimed at integrating humans and machines.